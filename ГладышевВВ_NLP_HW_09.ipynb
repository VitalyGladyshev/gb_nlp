{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNp4Cxx2CEbxFHgZt1nfNSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VitalyGladyshev/gb_nlp/blob/main/%D0%93%D0%BB%D0%B0%D0%B4%D1%8B%D1%88%D0%B5%D0%B2%D0%92%D0%92_NLP_HW_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ДЗ 9 Гладышев ВВ"
      ],
      "metadata": {
        "id": "anR9NmpDkkR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Генерация текста"
      ],
      "metadata": {
        "id": "_vODf8TSkqiW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QGN4O9vpkZXx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = '/content/evgenyi_onegin.txt'\n",
        "\n",
        "vocab = set()\n",
        "vocab.add(\"\\n\")\n",
        "vocab.add(\".\")\n",
        "vocab.add(\",\")\n",
        "with open(path_to_file, \"r\", encoding='utf-8', errors='ignore') as f:\n",
        "    for line in tqdm(f):\n",
        "        line = ''.join([ch for ch in list(line) if ch not in string.punctuation])\n",
        "        words = line.lower().strip().split(\" \")\n",
        "        for word in words:\n",
        "            vocab.add(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymJVntoUlo0W",
        "outputId": "676afd5d-3a66-402f-a68d-fd8ce422575b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6505it [00:00, 61421.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec = {}\n",
        "idx2word = np.array(list(vocab))\n",
        "\n",
        "for i, word in enumerate(vocab):\n",
        "    word2vec[word] = i"
      ],
      "metadata": {
        "id": "qwzkpP-UlyBR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec[\"\\n\"], word2vec[\".\"], idx2word[word2vec[\".\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNE9Z0OYl8N2",
        "outputId": "280c8c9a-e06b-4bc8-dbc6-ff1f7416080f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4630, 4024, '.')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_int = []\n",
        "with open(path_to_file, \"r\", encoding='utf-8', errors='ignore') as f:\n",
        "    for line in tqdm(f):\n",
        "        words = line.lower().strip().split(\" \")\n",
        "        for word in words:\n",
        "            point, comma = False, False\n",
        "            if \",\" in word:\n",
        "                comma = True\n",
        "            if \".\" in word:\n",
        "                point = True\n",
        "            word = ''.join([ch for ch in list(word) if ch not in string.punctuation])\n",
        "            text_as_int.append(word2vec[word])\n",
        "            if comma:\n",
        "                text_as_int.append(word2vec[\",\"])\n",
        "            if point:\n",
        "                text_as_int.append(word2vec[\".\"])\n",
        "        text_as_int.append(word2vec[\"\\n\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYMJcI5Zl-8P",
        "outputId": "68fc585f-607c-4f74-e65c-6bd21f8f4704"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6505it [00:00, 73917.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_int[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eP7S9CbmEnJ",
        "outputId": "a6234095-2cdf-4a93-ecb3-00635be6d06b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4713,\n",
              " 196,\n",
              " 524,\n",
              " 4630,\n",
              " 0,\n",
              " 4630,\n",
              " 3764,\n",
              " 1543,\n",
              " 4630,\n",
              " 929,\n",
              " 7366,\n",
              " 8000,\n",
              " 4630,\n",
              " 0,\n",
              " 4630]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_as_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQSzfJ5QmHqz",
        "outputId": "680ecd18-9673-42a7-8879-c29251384a0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35895"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train and target"
      ],
      "metadata": {
        "id": "CIKIUxpxmMRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The maximum length sentence you want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text_as_int)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "word_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in word_dataset.take(25):\n",
        "    print(idx2word[i.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zoykdc4WmLc9",
        "outputId": "5c029200-b6be-44aa-af79-852e1550b6d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "александр\n",
            "сергеевич\n",
            "пушкин\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "евгений\n",
            "онегин\n",
            "\n",
            "\n",
            "роман\n",
            "в\n",
            "стихах\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "не\n",
            "мысля\n",
            "гордый\n",
            "свет\n",
            "забавить\n",
            ",\n",
            "\n",
            "\n",
            "вниманье\n",
            "дружбы\n",
            "возлюбя\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = word_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6EayllDmVaa",
        "outputId": "9b798913-f2df-4ab1-c692-f1681a5b9459"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=TensorSpec(shape=(101,), dtype=tf.int32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in sequences.take(3):\n",
        "    print(' '.join(idx2word[item.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyhdzBfRn5Nq",
        "outputId": "5d0c49e1-7e06-4de8-c64c-c10c822ff13a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "александр сергеевич пушкин \n",
            "  \n",
            " евгений онегин \n",
            " роман в стихах \n",
            "  \n",
            " не мысля гордый свет забавить , \n",
            " вниманье дружбы возлюбя , \n",
            " хотел бы я тебе представить \n",
            " залог достойнее тебя , \n",
            " достойнее души прекрасной , \n",
            " святой исполненной мечты , \n",
            " поэзии живой и ясной , \n",
            " высоких дум и простоты \n",
            " но так и быть  рукой пристрастной \n",
            " прими собранье пестрых глав , \n",
            " полусмешных , полупечальных , \n",
            " простонародных , идеальных , \n",
            " небрежный плод моих забав , \n",
            " бессонниц , легких вдохновений , \n",
            " незрелых и увядших лет , \n",
            "\n",
            "ума холодных наблюдений \n",
            " и сердца горестных замет . \n",
            "  \n",
            " глава первая \n",
            "  \n",
            " и жить торопится и чувствовать спешит . \n",
            " кн . вяземский . \n",
            "  \n",
            " i \n",
            "  \n",
            " мой дядя самых честных правил , \n",
            " когда не в шутку занемог , \n",
            " он уважать себя заставил \n",
            " и лучше выдумать не мог . \n",
            " его пример другим наука \n",
            " но , боже мой , какая скука \n",
            " с больным сидеть и день и ночь , \n",
            " не отходя ни шагу прочь \n",
            " какое низкое коварство \n",
            " полуживого забавлять , \n",
            " ему подушки поправлять\n",
            ", \n",
            " печально подносить лекарство , \n",
            " вздыхать и думать про себя \n",
            " когда же черт возьмет тебя \n",
            "  \n",
            " ii \n",
            "  \n",
            " так думал молодой повеса , \n",
            " летя в пыли на почтовых , \n",
            " всевышней волею зевеса \n",
            " наследник всех своих родных . \n",
            " друзья людмилы и руслана \n",
            " с героем моего романа \n",
            " без предисловий , сей же час \n",
            " позвольте познакомить вас \n",
            " онегин , добрый мой приятель , \n",
            " родился на брегах невы , \n",
            " где , может быть , родились вы \n",
            " или блистали , мой читатель \n",
            " там некогда гулял и я\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "nrdUheHnn9P0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(' '.join(idx2word[input_example.numpy()])))\n",
        "    print('Target data:', repr(' '.join(idx2word[target_example.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuZIQl91oExf",
        "outputId": "a7944613-d9c6-4614-a7fc-6998fad107c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  'александр сергеевич пушкин \\n  \\n евгений онегин \\n роман в стихах \\n  \\n не мысля гордый свет забавить , \\n вниманье дружбы возлюбя , \\n хотел бы я тебе представить \\n залог достойнее тебя , \\n достойнее души прекрасной , \\n святой исполненной мечты , \\n поэзии живой и ясной , \\n высоких дум и простоты \\n но так и быть  рукой пристрастной \\n прими собранье пестрых глав , \\n полусмешных , полупечальных , \\n простонародных , идеальных , \\n небрежный плод моих забав , \\n бессонниц , легких вдохновений , \\n незрелых и увядших лет ,'\n",
            "Target data: 'сергеевич пушкин \\n  \\n евгений онегин \\n роман в стихах \\n  \\n не мысля гордый свет забавить , \\n вниманье дружбы возлюбя , \\n хотел бы я тебе представить \\n залог достойнее тебя , \\n достойнее души прекрасной , \\n святой исполненной мечты , \\n поэзии живой и ясной , \\n высоких дум и простоты \\n но так и быть  рукой пристрастной \\n прими собранье пестрых глав , \\n полусмешных , полупечальных , \\n простонародных , идеальных , \\n небрежный плод моих забав , \\n бессонниц , легких вдохновений , \\n незрелых и увядших лет , \\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KeJZGT3oIJI",
        "outputId": "6cec85d6-fef3-4cef-ea8d-84533da8c762"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "mOx7MdyeoLc8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.LSTM(rnn_units,   # tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "JtypfKXyoOfk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(\n",
        "            vocab_size=len(vocab),\n",
        "            embedding_dim=embedding_dim,\n",
        "            rnn_units=rnn_units,\n",
        "            batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "yddY7c9qoQiM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKrVLfAZoS9F",
        "outputId": "6ac376f3-5ba2-43a1-f998-9443c3dc6b9f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 8566) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHtI0wULoVkW",
        "outputId": "e952108b-0804-49f9-b1b1-9bd273b05122"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           2192896   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 8566)          8780150   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16220022 (61.87 MB)\n",
            "Trainable params: 16220022 (61.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "6ZxSxPpkoefq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input: \\n\", repr(\" \".join(idx2word[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\" \".join(idx2word[sampled_indices ])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8K8BBggohXl",
        "outputId": "f4285a67-a35d-4c3c-c1e2-9f2ef28e8551"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'мне делать с ней \\n всем наотрез одно и то же \\n нейду . и все грустит она , \\n да бродит по лесам одна . \\n  \\n xxvi \\n  \\n не влюблена ль она  в кого же \\n буянов сватался отказ . \\n ивану петушкову  тоже . \\n гусар пыхтин гостил у нас \\n уж как он танею прельщался , \\n как мелким бесом рассыпался \\n я думала пойдет авось \\n куда и снова дело врозь .  \\n что ж , матушка за чем же стало \\n в москву , на ярманку невест \\n'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'механик музами поздной предо никем толкователь поздно иным легкомыслия длинной проказам молчалив мостики des томила заморозил чуждался уборе осенняя боясь читал страстное лай роман пролить петрович страсть письмах херувим веках гостиной умолк памяти любимый недвижим красна песен земли основанный стыда приветствий кибитка постели слышно блещет вся лились моих владений легкий золотым толкует греметь доверчивость листья кием зимняя гений охота сельский второй глупостей эти благородство гребут будущий весело басен пела ежегодно простую книг поутру теснились привидений o капать города лукаво порядком приветом хладнокровно всем и стальные нагоняя равнодушна резвую северном ободренный гусары больным самдруг чередою роптанье ревнивом мнимый бесить свела нег'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение модели"
      ],
      "metadata": {
        "id": "KNr9YHxXomMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVUcOIriolLt",
        "outputId": "27c1c327-3351-4620-c0eb-af49cedd52ad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 8566)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       9.0553665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "XAyzaagcoskS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "eBLkZnpgovfK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100"
      ],
      "metadata": {
        "id": "In5U6hE_o0Pt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARGovXJUo3RX",
        "outputId": "fa87a6b4-9ab1-4be7-deb9-81bb4aa33a73"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 4s 317ms/step - loss: 8.3612\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 296ms/step - loss: 6.4789\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 3s 730ms/step - loss: 6.3747\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 3s 495ms/step - loss: 6.2272\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 416ms/step - loss: 6.1685\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 1s 300ms/step - loss: 6.1364\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 3s 641ms/step - loss: 6.1118\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 1s 290ms/step - loss: 6.0929\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 6.0729\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 3s 691ms/step - loss: 6.0437\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 4s 938ms/step - loss: 6.0113\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 3s 591ms/step - loss: 5.9595\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5.9280\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 5s 1s/step - loss: 5.8757\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 297ms/step - loss: 5.8434\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 5.7899\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 3s 641ms/step - loss: 5.7289\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 5s 1s/step - loss: 5.6978\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 353ms/step - loss: 5.6162\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 500ms/step - loss: 5.5776\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 353ms/step - loss: 5.5342\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 1s 316ms/step - loss: 5.4806\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 5.4526\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 1s 319ms/step - loss: 5.3840\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 1s 293ms/step - loss: 5.3359\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 5.2873\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 5.2717\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 5.1597\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 346ms/step - loss: 5.1135\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 349ms/step - loss: 5.0916\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 5.0192\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 1s 305ms/step - loss: 4.9817\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 3s 580ms/step - loss: 4.9363\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 4.8946\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 1s 299ms/step - loss: 4.8141\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 4.7639\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 347ms/step - loss: 4.7599\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 4.6991\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 4.6604\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 1s 296ms/step - loss: 4.6001\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 3s 706ms/step - loss: 4.5446\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 348ms/step - loss: 4.5499\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 355ms/step - loss: 4.4788\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 4.4147\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 3s 629ms/step - loss: 4.3809\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 331ms/step - loss: 4.3451\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 343ms/step - loss: 4.2862\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 1s 298ms/step - loss: 4.2636\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 3s 737ms/step - loss: 4.2102\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 497ms/step - loss: 4.1524\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 349ms/step - loss: 4.1271\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 3s 717ms/step - loss: 4.0715\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 4.0480\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 3.9746\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 380ms/step - loss: 3.9443\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 3.8997\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 1s 294ms/step - loss: 3.8507\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 3s 672ms/step - loss: 3.7933\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 331ms/step - loss: 3.7756\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 3.7029\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 3.6476\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 4s 923ms/step - loss: 3.5957\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 3.5652\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 3.5166\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 1s 306ms/step - loss: 3.4657\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 3.4154\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 1s 309ms/step - loss: 3.3551\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 4s 980ms/step - loss: 3.3131\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 311ms/step - loss: 3.2459\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 532ms/step - loss: 3.1907\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 1s 293ms/step - loss: 3.1740\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 4s 847ms/step - loss: 3.1022\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 310ms/step - loss: 3.0634\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 1s 296ms/step - loss: 3.0298\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 1s 306ms/step - loss: 2.9850\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 1s 304ms/step - loss: 2.9414\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 3s 583ms/step - loss: 2.8873\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 2.8342\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 1s 304ms/step - loss: 2.7799\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 1s 288ms/step - loss: 2.7355\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 4s 900ms/step - loss: 2.7141\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 2.6621\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 352ms/step - loss: 2.6034\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 3s 640ms/step - loss: 2.5674\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 1s 308ms/step - loss: 2.5349\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 3s 815ms/step - loss: 2.4941\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 338ms/step - loss: 2.4468\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 1s 290ms/step - loss: 2.4048\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 4s 879ms/step - loss: 2.3768\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 311ms/step - loss: 2.3273\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 2.2943\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 2.2497\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 358ms/step - loss: 2.2226\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 1s 302ms/step - loss: 2.1821\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 562ms/step - loss: 2.1572\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 1s 289ms/step - loss: 2.1241\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 1s 313ms/step - loss: 2.0915\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 2.0553\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 2.0352\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 2.0051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Генерация текста"
      ],
      "metadata": {
        "id": "MV5XgvwKpNAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BcuW86gRo5pI",
        "outputId": "1fa1ada2-0e82-4887-b334-1409cfdd9954"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_100'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "99bV-q-NpU_5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUyEnOf7pU-W",
        "outputId": "9178e042-7d8b-45eb-fd8e-c4e6d35a18e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 256)            2192896   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (1, None, 1024)           5246976   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 8566)           8780150   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16220022 (61.87 MB)\n",
            "Trainable params: 16220022 (61.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 500\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = []\n",
        "\n",
        "    words = start_string.lower().strip().split(\" \")\n",
        "    for word in words:\n",
        "        point, comma = False, False\n",
        "        if \",\" in word:\n",
        "            comma = True\n",
        "        if \".\" in word:\n",
        "            point = True\n",
        "        word = ''.join([ch for ch in list(word) if ch not in string.punctuation])\n",
        "        input_eval.append(word2vec[word])\n",
        "        if comma:\n",
        "            input_eval.append(word2vec[\",\"])\n",
        "        if point:\n",
        "            input_eval.append(word2vec[\".\"])\n",
        "    # input_eval = [word2vec[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = 0.5\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        # print(predicted_id)\n",
        "\n",
        "        text_generated.append(idx2word[predicted_id])\n",
        "\n",
        "    return (start_string + ' '.join(text_generated))"
      ],
      "metadata": {
        "id": "MdBWdS5IpU6a"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_string = u\"Уж небо осенью дышало, \\n Уж реже солнышко блистало, \\n Короче становился день,\"\n",
        "\n",
        "print(generate_text(model, start_string=start_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVeB-tyBpbkv",
        "outputId": "cdfd0928-d896-4d49-d268-ecd41124d80e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Уж небо осенью дышало, \n",
            " Уж реже солнышко блистало, \n",
            " Короче становился день,\n",
            " и прошлой наконец \n",
            " в деревне , ни балов , ни поэт , \n",
            " ни общежития искусством \n",
            "  \n",
            " v \n",
            "  \n",
            " но ей . какое взор \n",
            " в сем случае совсем неправ . \n",
            " что с ним в каком в ладони  \n",
            "  \n",
            " xiii \n",
            "  \n",
            " но , сплин мой страждущая творенье \n",
            " завез в них реке \n",
            " и в двадцать своей . \n",
            "  \n",
            " x \n",
            "  \n",
            " и вот ввели в ней . \n",
            "  \n",
            " xxxii \n",
            "  \n",
            " она мчались в воздухе нагретом \n",
            " татьяна \n",
            " не на почтовых , \n",
            " ни остротою , ни тоской , \n",
            " ни остротою , ни в очах , \n",
            " обнявшись , плакали оне . \n",
            " и деву этот лета \n",
            " я должна не находит \n",
            " в деревне , ни в розах , \n",
            " ни остротою , ни умом \n",
            " в деревне , на мельницу . \n",
            "  \n",
            " i \n",
            "  \n",
            " и наконец , преданный безделью , \n",
            " и , скачут и забор . \n",
            "  \n",
            " xxv \n",
            "  \n",
            " и вот ввели в тишине \n",
            " в общих мнений , лугами \n",
            " и вынулось колечко ей \n",
            " осталася длинный страшно в залог . \n",
            "  \n",
            " iii \n",
            "  \n",
            " татьяна точно умиленным .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jz9LDtmvpbiA"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}