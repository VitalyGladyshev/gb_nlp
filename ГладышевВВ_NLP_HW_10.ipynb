{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7ooFL3GZlYa5wvCePYGnH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VitalyGladyshev/gb_nlp/blob/main/%D0%93%D0%BB%D0%B0%D0%B4%D1%8B%D1%88%D0%B5%D0%B2%D0%92%D0%92_NLP_HW_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ДЗ 10 Гладышев ВВ"
      ],
      "metadata": {
        "id": "ut5OFBpdNkse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Модель seq2seq"
      ],
      "metadata": {
        "id": "PgYygoKGNwek"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRRiJQvl_deB"
      },
      "source": [
        "### Посимвольно"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "c1H-qhXLO1Yb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGedX9hbIIIn"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.manythings.org/anki/rus-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_98PAF1YOSDe",
        "outputId": "764c2597-14b3-474e-e653-ca29562eefc6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-06 14:49:27--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16065699 (15M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  15.32M  53.1MB/s    in 0.3s    \n",
            "\n",
            "2024-03-06 14:49:28 (53.1 MB/s) - ‘rus-eng.zip’ saved [16065699/16065699]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir rus-eng\n",
        "!unzip rus-eng.zip -d rus-eng/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOEyZNiKOWMq",
        "outputId": "d3a8ca56-4bf8-4589-bfde-fcd0178abbfa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus-eng/rus.txt         \n",
            "  inflating: rus-eng/_about.txt      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m9lMzpW4lbR"
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 70\n",
        "latent_dim = 256\n",
        "num_samples = 20000\n",
        "data_path = '/content/rus-eng/rus.txt'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r61xgg1g5zPt"
      },
      "source": [
        "# Собираем из текстов токены и делаем one-hot вектора на каждый токен\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters[:15], input_characters[-15:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0SBeEuyO_SQ",
        "outputId": "1a5f328c-b41d-44f4-fd13-9138de9b27ea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([' ', '!', '\"', '$', '%', '&', \"'\", ',', '-', '.', '0', '1', '2', '3', '4'],\n",
              " ['m', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvwaSyr37MEl"
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jstbUCYf72m6"
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_99USqX8bUp"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc7AzS6D8gzm",
        "outputId": "4b860434-8b3f-48f3-d9a5-44bc06052cbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "63/63 [==============================] - 7s 49ms/step - loss: 1.4685 - accuracy: 0.7544 - val_loss: 1.1857 - val_accuracy: 0.7398\n",
            "Epoch 2/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.9155 - accuracy: 0.7678 - val_loss: 0.9586 - val_accuracy: 0.7432\n",
            "Epoch 3/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.8067 - accuracy: 0.7774 - val_loss: 0.8870 - val_accuracy: 0.7604\n",
            "Epoch 4/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.7432 - accuracy: 0.8028 - val_loss: 0.8220 - val_accuracy: 0.7812\n",
            "Epoch 5/70\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.6820 - accuracy: 0.8211 - val_loss: 0.7549 - val_accuracy: 0.8002\n",
            "Epoch 6/70\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.6242 - accuracy: 0.8314 - val_loss: 0.7038 - val_accuracy: 0.8058\n",
            "Epoch 7/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.5848 - accuracy: 0.8373 - val_loss: 0.6716 - val_accuracy: 0.8108\n",
            "Epoch 8/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.5590 - accuracy: 0.8419 - val_loss: 0.6439 - val_accuracy: 0.8167\n",
            "Epoch 9/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.5393 - accuracy: 0.8462 - val_loss: 0.6229 - val_accuracy: 0.8221\n",
            "Epoch 10/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.5214 - accuracy: 0.8508 - val_loss: 0.6065 - val_accuracy: 0.8273\n",
            "Epoch 11/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.5074 - accuracy: 0.8545 - val_loss: 0.5927 - val_accuracy: 0.8317\n",
            "Epoch 12/70\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.4934 - accuracy: 0.8579 - val_loss: 0.5826 - val_accuracy: 0.8327\n",
            "Epoch 13/70\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.4826 - accuracy: 0.8608 - val_loss: 0.5714 - val_accuracy: 0.8364\n",
            "Epoch 14/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.4725 - accuracy: 0.8634 - val_loss: 0.5620 - val_accuracy: 0.8393\n",
            "Epoch 15/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.4632 - accuracy: 0.8662 - val_loss: 0.5524 - val_accuracy: 0.8425\n",
            "Epoch 16/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4544 - accuracy: 0.8686 - val_loss: 0.5461 - val_accuracy: 0.8434\n",
            "Epoch 17/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4477 - accuracy: 0.8704 - val_loss: 0.5397 - val_accuracy: 0.8454\n",
            "Epoch 18/70\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.4394 - accuracy: 0.8727 - val_loss: 0.5337 - val_accuracy: 0.8478\n",
            "Epoch 19/70\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.4321 - accuracy: 0.8749 - val_loss: 0.5310 - val_accuracy: 0.8476\n",
            "Epoch 20/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.4259 - accuracy: 0.8765 - val_loss: 0.5243 - val_accuracy: 0.8487\n",
            "Epoch 21/70\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.4191 - accuracy: 0.8786 - val_loss: 0.5150 - val_accuracy: 0.8523\n",
            "Epoch 22/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.4123 - accuracy: 0.8805 - val_loss: 0.5119 - val_accuracy: 0.8527\n",
            "Epoch 23/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4067 - accuracy: 0.8819 - val_loss: 0.5094 - val_accuracy: 0.8534\n",
            "Epoch 24/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.4006 - accuracy: 0.8838 - val_loss: 0.5014 - val_accuracy: 0.8564\n",
            "Epoch 25/70\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.3947 - accuracy: 0.8854 - val_loss: 0.4971 - val_accuracy: 0.8569\n",
            "Epoch 26/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.3886 - accuracy: 0.8873 - val_loss: 0.4936 - val_accuracy: 0.8579\n",
            "Epoch 27/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.3843 - accuracy: 0.8885 - val_loss: 0.4914 - val_accuracy: 0.8584\n",
            "Epoch 28/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.3787 - accuracy: 0.8899 - val_loss: 0.4870 - val_accuracy: 0.8605\n",
            "Epoch 29/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.3734 - accuracy: 0.8914 - val_loss: 0.4825 - val_accuracy: 0.8613\n",
            "Epoch 30/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.3678 - accuracy: 0.8932 - val_loss: 0.4786 - val_accuracy: 0.8635\n",
            "Epoch 31/70\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3637 - accuracy: 0.8943 - val_loss: 0.4803 - val_accuracy: 0.8630\n",
            "Epoch 32/70\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.3584 - accuracy: 0.8958 - val_loss: 0.4740 - val_accuracy: 0.8647\n",
            "Epoch 33/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.3532 - accuracy: 0.8973 - val_loss: 0.4721 - val_accuracy: 0.8647\n",
            "Epoch 34/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.3488 - accuracy: 0.8986 - val_loss: 0.4686 - val_accuracy: 0.8657\n",
            "Epoch 35/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.3448 - accuracy: 0.8996 - val_loss: 0.4660 - val_accuracy: 0.8658\n",
            "Epoch 36/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.3392 - accuracy: 0.9012 - val_loss: 0.4646 - val_accuracy: 0.8677\n",
            "Epoch 37/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.3351 - accuracy: 0.9025 - val_loss: 0.4626 - val_accuracy: 0.8675\n",
            "Epoch 38/70\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.3310 - accuracy: 0.9035 - val_loss: 0.4639 - val_accuracy: 0.8681\n",
            "Epoch 39/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.3268 - accuracy: 0.9047 - val_loss: 0.4590 - val_accuracy: 0.8689\n",
            "Epoch 40/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.3222 - accuracy: 0.9060 - val_loss: 0.4570 - val_accuracy: 0.8699\n",
            "Epoch 41/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.3178 - accuracy: 0.9070 - val_loss: 0.4564 - val_accuracy: 0.8705\n",
            "Epoch 42/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.3140 - accuracy: 0.9081 - val_loss: 0.4541 - val_accuracy: 0.8704\n",
            "Epoch 43/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.3092 - accuracy: 0.9096 - val_loss: 0.4527 - val_accuracy: 0.8717\n",
            "Epoch 44/70\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3059 - accuracy: 0.9105 - val_loss: 0.4529 - val_accuracy: 0.8714\n",
            "Epoch 45/70\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.3013 - accuracy: 0.9118 - val_loss: 0.4518 - val_accuracy: 0.8723\n",
            "Epoch 46/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.2973 - accuracy: 0.9127 - val_loss: 0.4529 - val_accuracy: 0.8720\n",
            "Epoch 47/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.2933 - accuracy: 0.9140 - val_loss: 0.4476 - val_accuracy: 0.8730\n",
            "Epoch 48/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.2894 - accuracy: 0.9151 - val_loss: 0.4494 - val_accuracy: 0.8736\n",
            "Epoch 49/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.2854 - accuracy: 0.9163 - val_loss: 0.4486 - val_accuracy: 0.8734\n",
            "Epoch 50/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.2826 - accuracy: 0.9171 - val_loss: 0.4464 - val_accuracy: 0.8743\n",
            "Epoch 51/70\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2784 - accuracy: 0.9182 - val_loss: 0.4477 - val_accuracy: 0.8747\n",
            "Epoch 52/70\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.2742 - accuracy: 0.9193 - val_loss: 0.4474 - val_accuracy: 0.8749\n",
            "Epoch 53/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.2696 - accuracy: 0.9208 - val_loss: 0.4447 - val_accuracy: 0.8755\n",
            "Epoch 54/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.2660 - accuracy: 0.9219 - val_loss: 0.4442 - val_accuracy: 0.8756\n",
            "Epoch 55/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.2626 - accuracy: 0.9228 - val_loss: 0.4494 - val_accuracy: 0.8751\n",
            "Epoch 56/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.2587 - accuracy: 0.9239 - val_loss: 0.4457 - val_accuracy: 0.8761\n",
            "Epoch 57/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.3122 - accuracy: 0.9119 - val_loss: 0.5811 - val_accuracy: 0.8407\n",
            "Epoch 58/70\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.3650 - accuracy: 0.8921 - val_loss: 0.4563 - val_accuracy: 0.8690\n",
            "Epoch 59/70\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3053 - accuracy: 0.9097 - val_loss: 0.4418 - val_accuracy: 0.8740\n",
            "Epoch 60/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.2835 - accuracy: 0.9164 - val_loss: 0.4395 - val_accuracy: 0.8755\n",
            "Epoch 61/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.2709 - accuracy: 0.9201 - val_loss: 0.4383 - val_accuracy: 0.8771\n",
            "Epoch 62/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.2629 - accuracy: 0.9224 - val_loss: 0.4396 - val_accuracy: 0.8769\n",
            "Epoch 63/70\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.2566 - accuracy: 0.9244 - val_loss: 0.4425 - val_accuracy: 0.8761\n",
            "Epoch 64/70\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.2512 - accuracy: 0.9261 - val_loss: 0.4409 - val_accuracy: 0.8780\n",
            "Epoch 65/70\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.2467 - accuracy: 0.9274 - val_loss: 0.4414 - val_accuracy: 0.8777\n",
            "Epoch 66/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.2423 - accuracy: 0.9286 - val_loss: 0.4431 - val_accuracy: 0.8778\n",
            "Epoch 67/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.2382 - accuracy: 0.9298 - val_loss: 0.4451 - val_accuracy: 0.8774\n",
            "Epoch 68/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.2347 - accuracy: 0.9309 - val_loss: 0.4419 - val_accuracy: 0.8786\n",
            "Epoch 69/70\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.2315 - accuracy: 0.9316 - val_loss: 0.4431 - val_accuracy: 0.8784\n",
            "Epoch 70/70\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.2277 - accuracy: 0.9328 - val_loss: 0.4445 - val_accuracy: 0.8784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwb_ftoE_8Ca"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq, verbose=None)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value, verbose=None)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl8LUX41ABIv",
        "outputId": "abae7aba-1de1-4769-b934-c1ec9649a555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for seq_index in range(0, 20000, 500):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Подожди.\n",
            "\n",
            "-\n",
            "Input sentence: Who ate?\n",
            "Decoded sentence: Кто это сделал?\n",
            "\n",
            "-\n",
            "Input sentence: Touch it.\n",
            "Decoded sentence: Потрогай её.\n",
            "\n",
            "-\n",
            "Input sentence: I'm dirty.\n",
            "Decoded sentence: Я прованился.\n",
            "\n",
            "-\n",
            "Input sentence: Tom's shy.\n",
            "Decoded sentence: Том в стреня.\n",
            "\n",
            "-\n",
            "Input sentence: I envy you.\n",
            "Decoded sentence: Я вазадую тебя.\n",
            "\n",
            "-\n",
            "Input sentence: It's green.\n",
            "Decoded sentence: Оно застренно.\n",
            "\n",
            "-\n",
            "Input sentence: We'll cook.\n",
            "Decoded sentence: Мы пойдём.\n",
            "\n",
            "-\n",
            "Input sentence: Have a look.\n",
            "Decoded sentence: Поеходи.\n",
            "\n",
            "-\n",
            "Input sentence: I saved you.\n",
            "Decoded sentence: Я вас разбила.\n",
            "\n",
            "-\n",
            "Input sentence: Is it there?\n",
            "Decoded sentence: Он странно?\n",
            "\n",
            "-\n",
            "Input sentence: Stop crying.\n",
            "Decoded sentence: Перестань хратиться!\n",
            "\n",
            "-\n",
            "Input sentence: We miss you.\n",
            "Decoded sentence: Мы слышали это.\n",
            "\n",
            "-\n",
            "Input sentence: Are you tall?\n",
            "Decoded sentence: Ты в порядке?\n",
            "\n",
            "-\n",
            "Input sentence: Hey, wake up!\n",
            "Decoded sentence: Эй, проснить!\n",
            "\n",
            "-\n",
            "Input sentence: I was lonely.\n",
            "Decoded sentence: Я была занят.\n",
            "\n",
            "-\n",
            "Input sentence: I'm very hot.\n",
            "Decoded sentence: Я очень старый.\n",
            "\n",
            "-\n",
            "Input sentence: Must I hurry?\n",
            "Decoded sentence: Мне спеть идти получилось.\n",
            "\n",
            "-\n",
            "Input sentence: They're ugly.\n",
            "Decoded sentence: Они постали.\n",
            "\n",
            "-\n",
            "Input sentence: We have time.\n",
            "Decoded sentence: У нас есть вино.\n",
            "\n",
            "-\n",
            "Input sentence: You're scary.\n",
            "Decoded sentence: Вы слешим.\n",
            "\n",
            "-\n",
            "Input sentence: Don't be mean.\n",
            "Decoded sentence: Не ходи кричны.\n",
            "\n",
            "-\n",
            "Input sentence: I am divorced.\n",
            "Decoded sentence: Я в умуску.\n",
            "\n",
            "-\n",
            "Input sentence: I miss Boston.\n",
            "Decoded sentence: Я скучаю по помощею.\n",
            "\n",
            "-\n",
            "Input sentence: I'll get some.\n",
            "Decoded sentence: Я пойду спочем.\n",
            "\n",
            "-\n",
            "Input sentence: Is Tom around?\n",
            "Decoded sentence: Том болен?\n",
            "\n",
            "-\n",
            "Input sentence: Listen to Tom.\n",
            "Decoded sentence: Послушайте мне.\n",
            "\n",
            "-\n",
            "Input sentence: Stop scowling.\n",
            "Decoded sentence: Перестань проваться.\n",
            "\n",
            "-\n",
            "Input sentence: Tom has a cat.\n",
            "Decoded sentence: У Тома есть корока.\n",
            "\n",
            "-\n",
            "Input sentence: Turn the page.\n",
            "Decoded sentence: Переверни наму.\n",
            "\n",
            "-\n",
            "Input sentence: Who was wrong?\n",
            "Decoded sentence: Кто тебя поделжен?\n",
            "\n",
            "-\n",
            "Input sentence: Aren't you Tom?\n",
            "Decoded sentence: Вы не Том?\n",
            "\n",
            "-\n",
            "Input sentence: Do you promise?\n",
            "Decoded sentence: Ты меняте потробовать?\n",
            "\n",
            "-\n",
            "Input sentence: He is handsome.\n",
            "Decoded sentence: Он нановится.\n",
            "\n",
            "-\n",
            "Input sentence: I got up early.\n",
            "Decoded sentence: Я полазорали.\n",
            "\n",
            "-\n",
            "Input sentence: I said shut up!\n",
            "Decoded sentence: Я сказал себяю слабой меня полинился.\n",
            "\n",
            "-\n",
            "Input sentence: I'm an old man.\n",
            "Decoded sentence: Я в нанце.\n",
            "\n",
            "-\n",
            "Input sentence: It was serious.\n",
            "Decoded sentence: Это было не постоное.\n",
            "\n",
            "-\n",
            "Input sentence: Mary is a girl.\n",
            "Decoded sentence: Мэри скриния.\n",
            "\n",
            "-\n",
            "Input sentence: Tell everybody.\n",
            "Decoded sentence: Скажите клю-нибу.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZRqFdQS_YsX"
      },
      "source": [
        "## Уровень слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmudPG4KDdZi"
      },
      "source": [
        "import re\n",
        "# import tensorflow.compat.v1 as tf\n",
        "import tensorflow as tf"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBWA4KXL_9jE"
      },
      "source": [
        "# tf.enable_eager_execution()\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w = w.strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "def preprocess_sentence_rus(w):\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^а-яА-Я?.!,¿]+\", \" \", w)\n",
        "    w = w.strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(preprocess_sentence(input_text))\n",
        "    target_texts.append(preprocess_sentence_rus(target_text))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izbPKil_9mNo"
      },
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "    return tensor, lang_tokenizer"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRwmxhemD1Tg"
      },
      "source": [
        "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
        "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9IIoFYLD9rZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9kEMr2mECVA"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAqyjTCDEY_l"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.lstm(x, initial_state = hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.lstm(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue6tmjOpHVTy"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQFSakRwFjph"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6U32GBYGn6q",
        "outputId": "144c7997-79d1-45ea-d132-0298631ced03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "EPOCHS = 35\n",
        "for epoch in range(EPOCHS):\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss 1.6509\n",
            "Epoch 2 Loss 1.1737\n",
            "Epoch 3 Loss 0.9304\n",
            "Epoch 4 Loss 0.7179\n",
            "Epoch 5 Loss 0.5353\n",
            "Epoch 6 Loss 0.4087\n",
            "Epoch 7 Loss 0.3243\n",
            "Epoch 8 Loss 0.2696\n",
            "Epoch 9 Loss 0.2349\n",
            "Epoch 10 Loss 0.2100\n",
            "Epoch 11 Loss 0.1935\n",
            "Epoch 12 Loss 0.1805\n",
            "Epoch 13 Loss 0.1727\n",
            "Epoch 14 Loss 0.1667\n",
            "Epoch 15 Loss 0.1602\n",
            "Epoch 16 Loss 0.1540\n",
            "Epoch 17 Loss 0.1503\n",
            "Epoch 18 Loss 0.1469\n",
            "Epoch 19 Loss 0.1433\n",
            "Epoch 20 Loss 0.1411\n",
            "Epoch 21 Loss 0.1411\n",
            "Epoch 22 Loss 0.1381\n",
            "Epoch 23 Loss 0.1345\n",
            "Epoch 24 Loss 0.1324\n",
            "Epoch 25 Loss 0.1306\n",
            "Epoch 26 Loss 0.1297\n",
            "Epoch 27 Loss 0.1274\n",
            "Epoch 28 Loss 0.1263\n",
            "Epoch 29 Loss 0.1243\n",
            "Epoch 30 Loss 0.1221\n",
            "Epoch 31 Loss 0.1203\n",
            "Epoch 32 Loss 0.1188\n",
            "Epoch 33 Loss 0.1177\n",
            "Epoch 34 Loss 0.1171\n",
            "Epoch 35 Loss 0.1179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q75W9BaG89n"
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence, attention_plot\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "    #ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    #ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "\n",
        "def translate(sentence, show=True):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}\\n'.format(result))\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    if show:\n",
        "        plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwK7EUOQHzFT",
        "outputId": "ac60072c-fa57-413d-ace1-350a2060ed54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['f', 'char']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtX1PzaHH7ZO",
        "outputId": "f3ad5a5c-e993-497e-c120-f21c967269d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "translate(u'good morning')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> good morning <end>\n",
            "Predicted translation: доброе утро . <end> \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-6ae2198bd1af>:38: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "<ipython-input-45-6ae2198bd1af>:39: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAN1CAYAAACAVBYQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCtUlEQVR4nO3deZhXdf3//8cMq6igiIAoAuLW4oYbBiaiiZJbue9Yqdk3Q/uVfiw/SJlhZX6zrG+lGYpBan2C1ETFQmVTMVyyRAU1EAHDBMJAYOb3R5fziVh8sc17GG6365qr633Oa2aeM9c73nfPnHPeVbW1tbUBAADeV3WlBwAAgE2FeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKBQ00oPAACN2aOPPvq+a6qrq9O6devsuuuuadWqVT1MBayrqtra2tpKDwEAjVV1dXWqqqqK137sYx/Ld77znXzoQx/ayJMB60I8A8BGNHjw4DzxxBMZPXp09thjj3zkIx9Jhw4dMmfOnEycODEvvPBCjjnmmHTv3j1//OMfM2HChLRp0yaPP/54dt9990qPD/wH8QwAG9Fjjz2Wj33sY/nxj3+cAQMGrLT/tttuy8UXX5wHH3wwvXv3zh133JFzzz03Z599dm6//fb6HxhYI/HMJmHhwoVp1qxZWrZsWelRANZKnz59sv322+fuu+9e7ZpTTjklb775ZsaOHZsk6du3b1588cXMnDmznqYESrnbBg3e1KlTs80222T//fev9CgAa+2pp57KHnvsscY1e+yxR5566qm6x/vuu2/efPPNjT0asA7EMw3esGHDUltbmxdeeCGTJ0+u9DgAa6V58+Z5+umn17hmypQpadasWd3j5cuXZ8stt9zIkwHrQjzT4N1xxx3ZbbfdUl1dnWHDhlV6HIC1cuSRR+b+++/Pt771rSxdunSFfUuXLs13vvOdjB49OkcddVTd9j//+c/Zeeed63tUoIBznmnQHnnkkfTt2zc33HBDRo8enT/+8Y+ZNWtWmjRpUunRAIq89tprOeSQQzJnzpy0b98+BxxwQNq3b5+5c+fmqaeeqts+adKkdOnSJbNnz86HP/zhXHzxxbnmmmsqPT7wH8QzDdqnP/3pDBs2LK+//npGjx6dAQMGZNSoUTn22GMrPRpAsVmzZuWKK67Ir371qyxZsqRue4sWLXLyySdnyJAh2WmnnSo4IVBKPNNgLV68OB06dEivXr3yu9/9LosWLUqHDh3y8Y9/PHfeeWelxwNYa++++26mTp2aBQsWpHXr1tljjz3SvHnzSo8FrAVvz02DNXLkyCxcuDBnn312kmTLLbfM8ccfn5EjR2b+/Plp06ZNhScEWDvNmzfPXnvtVekxgPXggkEarNtvvz1bb711PvGJT9RtO/vss7N48eI13i8VAGBjEc80SHPmzMlDDz2UE088MVtssUXd9n79+mX77bf3rlvAJmXMmDHp379/tt9++zRr1ixNmjRZ6aNpU38MZsO555578uSTT1Z6jEbJ/1NpkIYPH56ampq6Uzbe06RJk5x66qn50Y9+lFdeeSXdunWr0IQAZX7961/ntNNOS01NTbp06ZI999xTKLNRPfrooznhhBPSvn37vP766+5QtYG5YJAGqUePHpk7d25mzJiRqqqqFfZNmjQpH/nIR/K1r30t//3f/12hCQHK7LPPPpk+fXpGjRqVvn37VnocNgOf+cxncuutt6aqqsodqjYCp23Q4PzpT3/K008/ndNPP32lcE6Snj17ZpdddvGGKcAmYerUqTn99NOFM/Vi8eLF+dWvfpU+ffpkyy239Fq5Efi7EQ1Ot27d8sorr2T77bdf7ZpJkyZl0aJF9TgVwLrZbrvt0qpVq0qPwWZi1KhRWbhwYS688MJ07tw5d999d92tEdkwHHmmwdlyyy3TpUuXNb7YtGvXLl26dKnHqQDWzcknn5wxY8Zk2bJllR6FzcCwYcPq7lR11llnuUPVRiCeaZAeffTR/PWvf13jmhkzZuTRRx+tp4kA1s03v/nNbLPNNjnttNPe9981WB9z587Ngw8+mE984hNp0aJFjjzyyHTs2NEdqjYw8UyDdPjhh2fo0KFrXHP77bfn8MMPr5+BANbRXnvtlb/+9a8ZOXJkunXrlu222y677LLLSh/du3ev9Khs4kaMGJHly5fnnHPOSZJUV1fntNNOy7hx4/Lqq69WdrhGRDzTIJXcBKampmaVFxQCNCQ1NTVp2rRpdt555+y8885p3bp1amtrV/qoqamp9Khs4m6//fZ06tRphYtTzznnnNTW1uaOO+6o4GSNiwsG2WS99NJL3qIbaPAc8aM+/PnPf86UKVPypS99aYXtPXr0yB577JFhw4blqquuqtB0jYt4psH41Kc+tcLjkSNHrvJFZ/ny5XXnOx9zzDH1NB0ANFy33357qqqqVnpzsSQ588wzM3jw4Dz++OM5+OCDKzBd4+JNUmgwqqv/9yyiqqqqNZ66UVVVlQMPPDB33HFHdt111/oYDwAapNra2uy8885p27ZtnnnmmZX2v/LKK+nevXs+97nP5aabbqrAhI2LI880GK+88kqSf/0jsMsuu+TSSy/NwIEDV1rXpEmTbLvtttlyyy3re0SA9/X1r389VVVV+T//5/+kbdu2+frXv170eVVVVd41lXUyefLkNG3aNBdddNEq93fr1i3HHntsHn/88dTW1rpeaD058kyDdNttt2W//fbL3nvvXelRANZKdXV1qqqq8pe//CW77777Cn9VW5OqqqosX758I08HrC/xTINUXV2dM844I7/4xS8qPQrAWnnkkUeSJAcffHBatmxZ97jEYYcdtrHGAjYQp23QILVp0yadO3eu9BgAa+0/A1gQQ+MinmmQDjzwwFVe9AAAZL3eYfejH/3oBpxk8+O0DRqkiRMnpk+fPrn55ptz7rnnVnocgPW2bNmyTJ06NW+//fZqz20WNZR679z6deHc+vXjyDMN0kMPPZQ+ffrk/PPPzw9+8IMceOCB6dChw0r/ULg6HWjoamtrM2jQoPzgBz/IwoUL17hW1FBq0KBBK70mTpo0KQ888EB222239OrVKx06dMicOXMyYcKEvPjii+nXr1969uxZoYkbD0eeaZBcnQ40Fl//+tczePDgbLPNNjnhhBOy0047pWnTVR+7uvrqq+t5OhqLxx57LB/72Mdy00035dOf/vQKYV1bW5ubb745AwcOzEMPPZTevXtXcNJNn3imQXJ1Ohvauv6Js6qqKsuWLdsIE7G56Nq1a6qqqjJ58uRst912lR6HRqpPnz7Zbrvt8utf/3q1az75yU/m73//e/7whz/U42SNj9M2aJAEMRvaRz/60ZXi+e9//3ueffbZNGnSJJ07d677E+eMGTOyfPny7L333tl2220rNDGNxezZs3PxxRcLZzaqp556apVvLPbvPvCBD+T73/9+PU3UeIlnYLMwduzYFR7PnDkzvXr1yplnnplvfvOb2Xnnnev2/fWvf82VV16Z8ePH5957763nSWlsunXrlgULFlR6DBq55s2bZ8qUKWtcM2XKlDRv3ryeJmq8nLZBgzdjxozMmjUrS5YsWeV+V6ezLk4//fS8+uqrmTRp0mrX9OzZM926dcuIESPqcTIam+9///u59tpr89xzz6V9+/aVHodG6owzzshdd92Va6+9Nl/84hdXiOR333033/3ud3PVVVfltNNOy/Dhwys46aZPPNNg3XPPPfnyl7+cl156aY3rXDDIumjXrl0uuuiiXHvttatd85WvfCU333xz3nzzzXqcjMbmtddey5e+9KVMmTIlgwYNSo8ePdK6detVrv33v4DA2pg5c2Z69uyZN954I+3bt88BBxyQ9u3bZ+7cuZk8eXLmzp2bTp06ZeLEidlpp50qPe4mzWkbNEhjx47NJz7xiXTs2DGf//zn84Mf/CCHHXZY9txzz4wbNy7PP/98jj322Oy///6VHpVN1OLFi/PGG2+scc2sWbPyz3/+s54morHq1q1bqqqqUltbm/PPP3+161ycyvrYaaedMnny5PzXf/1X7rrrrtx33311+1q2bJlzzjkn1113XTp27FjBKRsHR55pkI4++uhMmjQpU6dOTYcOHVJdXZ3Bgwdn0KBBSZIhQ4bkG9/4RsaPH5999923ssOySTrssMPy5JNP5uGHH84hhxyy0v4JEybkiCOOSM+ePV2ZznoZMGBA8Z1efv7zn2/kadgcLF26NFOnTs38+fPTpk2b7L777s513oDEMw3Sdtttl+OOOy5Dhw5N8q/bjA0aNCiDBw+uW9O7d++0bds2v/3tbyszJJu0cePG5Ygjjsjy5ctz3HHHpXfv3nV/4nzsscdy7733pmnTpnn44YfTq1evSo8LQAPhtA0apHfeeSc77rhj3eMWLVqsdLV6z549HaVhnfXu3Tu/+93vcuGFF2bUqFEZNWpU3Z/Wk3/9qf2nP/2pcGa97bLLLunfv39uuummSo8CbADimQapY8eOK1ykteOOO+b5559fYc28efNcLMh6OeKII/Lyyy9n3LhxeeaZZ+r+xLnPPvukd+/e6/SmKvCf/va3v2Xrrbeu9BhsBsaMGZMbbrghTz75ZN5+++3U1NSstMa59etPPNMg7bPPPvnTn/5U9/jwww/PbbfdlhEjRuT444/PuHHjctddd7lgkPVWVVWVQw89NIceemilR6GR2nvvvfPiiy9WegwauV//+tc57bTTUlNTky5dumTPPfdc7dvAs36c80yDdOutt+bzn/98/vKXv6RLly555ZVXsv/++2f+/Pl1a5o2bZqHHnrIfZ5Zb8uWLcvUqVOzYMGCtG7dOnvssYcXHTaYe+65JyeddFIeeOCBHH744ZUeh0Zqn332yfTp0zNq1Kj07du30uM0auKZTca0adNyww03ZPr06enSpUs++9nPutMG6+Wtt97KFVdckeHDh2fx4sV127fYYouceeaZGTJkiLdUZr3dfvvtueuuu/LAAw/kxBNPzIEHHpgOHTqs8rSgc889twIT0hi8dzu6m2++udKjNHriGdgsvfXWW+nZs2defvnltG3bNgcccEB22GGHzJ49O5MnT868efOy2267ZeLEiWnbtm2lx2UTVl1dvcLFqO/593iura1NVVWV6zhYZzvuuGNOPvnk3HjjjZUepdHzd0kapE996lM58cQTc/zxx692zb333pv/+Z//ya233lqPk9FYXHPNNXn55Zfz5S9/OYMGDcqWW25Zt++dd97JNddck29961u59tpr893vfreCk7Kpc1cg6sPJJ5+cMWPGZNmyZU4728gceaZB+s83RVmVa6+9NoMGDXKkhnWyyy67pGvXrvn973+/2jV9+/bNq6++munTp9fjZABrb9GiRTnqqKPSsWPH/N//+3+91ftG5D9N2GQtXrzYf12zzmbNmpUzzjhjjWsOOeSQTJgwoZ4mAlh3e+21V5YuXZpJkyZl5MiR2WabbdKmTZuV1lVVVWXatGkVmLDxUB40WKu7x25tbW1mzJiR+++/P506darnqWgs2rRpk9dee22Na1577bVVvvjAunj11Vfzi1/8Ik8//XTdnV323XffnHXWWenatWulx2MTV1NTk6ZNm65wxHlVJxc44WD9OW2DBuO9i2qS/714Zk1qa2tzxRVXZMiQIfUxHo3MqaeemlGjRuW+++7LkUceudL+hx9+OP3798+JJ56YO++8swIT0pjceOONufzyy7Ns2bKV4qVZs2b59re/nYEDB1ZoOmBtiGcajD59+tQF86OPPpqdd955lUdjmjRpkrZt26Zv37654IIL0qRJk3qelMbg+eefz0EHHZTFixenf//+Oeyww9KhQ4fMmTMnY8eOzf33359WrVpl0qRJ+dCHPlTpcdmE3XvvvTn++OPTrl27XHbZZTn88MPr7uzyhz/8ITfccEPmzZuX3/72t/n4xz9e6XGB9yGeaZBKLhiE9TVu3LgMGDCg7oLAf7+dWPfu3TN06ND06tWrkiPSCPTt2zfPPvtsnn766ey0004r7Z8xY0b222+/7LPPPnn44YcrMCGNzZ///Oe88MILWbRoUc4555xKj9PoiGdgs1ZbW5vx48dnypQpdeeh7rfffunVq9f7njoEJbbZZpucddZZ+eEPf7jaNZ/73OcyfPjwvP322/U3GI3Ok08+mQsuuCDPPfdc3bb37kj16KOP5uijj84vf/nLNd4GlvfngkEarJqamlRXV6+wbeLEibn33nvTsmXLnH/++as8igNro6qqKr17907v3r0rPQqN1LvvvrvCfcRXZauttsq7775bTxPRGD3//PPp27dvqqurc9lll+WFF17I/fffX7f/0EMPTbt27XL33XeL5/VU/f5LoP5ddtlladWq1QpHYX71q1/l0EMPzZAhQ3L11VenR48emTlzZuWGpNFYtmxZnn/++UycODHPP/98li1bVumRaER233333HPPPat9Xi1btiz33ntvdt9993qejMbk6quvTpI89dRTuf7663PggQeusL+qqiqHHHJInnzyyUqM16iIZxqkP/zhD+nbt2+22Wabum2DBg1KmzZtcvvtt+fb3/52/v73v+f666+v3JBs8t56661ccMEFadOmTfbee+/07t07e++9d7bZZptceOGFmTdvXqVHpBE499xzM3Xq1PTr1y9PPfXUCvsmT56cY445JlOnTs15551XoQlpDB555JGcdNJJ2XXXXVe7Zuedd84bb7xRj1M1Tk7boEGaMWNGDjvssLrHr7zySl544YVcffXVOfvss5Mkjz32WEaPHl2pEdnEvfXWW+nZs2defvnltG3bNoceemjdHRAmT56cW265JY888kgmTpyYtm3bVnpcNmEDBw7Mo48+mt/+9rc56KCD0qpVq7Rv3z5z587NO++8k9ra2pxwwgluVcd6WbhwYdq3b7/GNf/85z+9K+8G4MgzDdKiRYtWOEfwkUceSVVVVY455pi6bR/84AedtsE6u+aaa/Lyyy/ny1/+cl577bWMHj06P//5z3P//ffntddeyxVXXJGXXnop1157baVHZRPXpEmTjBw5MkOHDk2fPn3SvHnz/PWvf03z5s1z+OGH57bbbstvfvObla7xgLXRuXPnFS4UXJU//vGP6d69ez1N1Hj5fyoNUqdOnTJ16tS6x6NHj85WW22V/fffv27bggUL0qJFi0qMRyMwatSo9OnTJ9/61rdWupirVatWGTJkSPr06ZPf/OY3FZqQxubcc8/Nww8/nHnz5mXp0qWZN29exowZ41ZibBDHHntsHnzwwYwZM2aV+++6665MmjQpJ554Yv0O1gg5bYMG6bDDDsuIESNy0003pWXLlvmf//mfnHjiiSu8Icq0adPcbYN1NmvWrJxxxhlrXHPIIYdkwoQJ9TQRjd3y5cszc+bMzJo1K0uXLl3lmo9+9KP1PBWNxVe+8pX86le/Sv/+/XPeeedl9uzZSZIf/ehHmThxYkaMGJGuXbvmi1/8YoUn3fS5zzMN0ssvv5wDDzwwCxYsSG1tbbbccss8/vjj+eAHP5jkX+d2dejQIQMGDMiPfvSjCk/LpqhDhw752Mc+ljvuuGO1a84+++w89NBDmTNnTj1ORmNTU1OTb37zm7nxxhvz1ltvrXGt81FZH9OnT88555yTiRMnrrTv4IMPrgto1o8jzzRIu+66a/785z/n17/+dZLkuOOOS5cuXer2v/TSS7noooty5plnVmpENnGHHXZY7r777gwYMCBHHnnkSvsffvjh3H333f7EyXq78sor853vfCft27fP+eefnx122CFNm3r5ZcPbZZddMn78+Dz99NOZNGlS3nrrrbRu3ToHH3zwSreuY9058gxslp5//vkcdNBBWbx4cfr375/DDjssHTp0yJw5czJ27Njcf//9adWqVSZNmpQPfehDlR6XTVjHjh2z7bbb5sknn8xWW21V6XGA9SSeaXBmzZqVyZMnp0ePHqs9p/nJJ5/M7Nmzc+yxx3oLZdbZuHHjMmDAgEyfPj3Jv95E4L1/Ert3756hQ4emV69elRyRRmCrrbbKZz/7WfelZ6Pxulm/xDMNzsyZM9OlS5ecf/75ueWWW1bav3z58uy4447Zeeed88QTT1RgQhqT2trajB8/PlOmTMmCBQvSunXr7LfffunVq5cXGDaIj3zkI+natWuGDx9e6VFopLxu1i/xTIPUt2/fTJkyJbNnz17pdnSjR49O//79c+ONN+aSSy6p0IQAZe67776ccsopGTduXHr06FHpcWikvG7WH1cs0CCde+65eeSRR3LPPffk5JNPXmHfL37xizRr1szFgqyXT33qU++7prq6Oq1bt84ee+yRY489NjvuuGM9TEZj8/GPfzxDhw7NMccck+OPPz777LNPWrduvcq15557bj1PR2PhdbP+OPJMg/SPf/wjHTt2zBFHHJFRo0bVbX/nnXfSoUOHHH744fntb39bwQnZ1FVXV9edlrGqfwb//fznJGnatGkGDRqUq666qt5mpHFYsmRJPvOZz2T48OF1z6n/PCWotrY2VVVVblXHOvO6WX8ceaZB2mqrrXLCCSfk17/+dd566620bds2yb/eFe6dd95xdIb1Nm3atFx66aV54oknMnDgwPTq1avubhvjx4/P97///Rx00EH56le/mmeeeSbf+MY3cvXVV2e33XbLaaedVunx2YR88YtfzC9+8YvsvffeOfnkk92qjo3C62b9ceSZBuu9c7R++MMf5uKLL07yrz9/Tpw4MbNnz07z5s0rPCGbsuuuuy7f+9738swzz6RDhw4r7Z89e3b23XfffPGLX8zll1+e119/PR/84Aez77775pFHHqnAxGyq2rdvny5dumTixImimY3K62b9qK70ALA6Rx11VDp27Jhhw4YlSf72t7/loYceyimnnOIfANbbz372s5x66qmrDOfkX/fmPeWUU3LzzTcnSXbccccce+yxeeaZZ+pzTBqBxYsX5/DDDxfObHReN+uHeKbBqq6uzhlnnJHHH38806dPz5133pnly5fnnHPOqfRoNAIzZ85c6Yr0/9SyZcvMnDmz7vHOO++cxYsXb+zRaGT233//vPzyy5Ueg82A1836IZ5p0M4999zU1tbmjjvuyB133JGuXbumd+/elR6LRmDHHXfMyJEjVxvDixcvzsiRI1e4w8bcuXOz7bbb1teINBLf/OY3M3r06Nx7772VHoXNgNfNjc/fkGjQ9tlnn+y11175f//v/2Xu3LnudMAG8+lPfzpf/epX07t37wwaNCi9evXKdtttl3nz5mX8+PH5+te/nunTp+eaa66p+5zHHnss++yzTwWnZlP00EMPpU+fPjnhhBPSt2/f1d6qrqqqKv/93/9dgQlpTLxubnwuGKTBu/7663P55ZenqqoqL774Yrp3717pkWgEli9fnvPPPz933HFH3W3DqqurU1NTk+Rftw4788wzc/vtt6e6ujpz5szJddddl6OPPjr9+vWr5OhsYqqry/7I61Z1bCheNzcu8UyD98Ybb+QjH/lI9t577xXuXQkbwu9///sMGzYszz77bN3bc++zzz4566yzcsQRR1R6PBqBtbk7y2GHHbYRJ2Fz4XVz4xLPAABQyAWDAABQSDwDAEAh8UyDt2TJkgwePDhLliyp9Cg0Yp5n1AfPM+qD59nG5ZxnGrwFCxakTZs2mT9//ipv7wQbgucZ9cHzjPrgebZxOfIMAACFxDMAABTyDoP1rKamJrNmzcrWW29d98YMrNmCBQtW+F/YGDzPqA+eZ9QHz7O1V1tbm4ULF6ZTp07v+8ZGznmuZzNnzkznzp0rPQYAAP9hxowZ2Wmnnda4xpHnerb11lsnSQ5tcnyaVjWr8DQ0Zk3abVfpEdgM3P3omEqPwGbgpP0OrvQINHLLapfm0Xd+VddpayKe69l7p2o0rWomntmomlQ3r/QIbAZab+3SGTa+plX+PaN+lJxS6189AAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgEJNKz3A+5k9e3bGjRuXOXPm5M0338zf/va3fPnLX06XLl0qPRoAAJuZBhvPL774Yi655JKMGTMmNTU1ddurq6tz0EEH5dxzz63gdAAAbI4aZDy/+OKLOeSQQ7JgwYJcccUV+dSnPpXu3bunqqqq0qMBALAZa5Dx/OlPfzoLFy7Mvffem379+lV6HAAASNIALxh87rnnMm7cuHzhC18QzgAANCjrFM+vvvpqqqqqVvuxKn/6059y6qmnpn379mnRokW6deuWSy+9NPPmzVth3YQJE5Ike+yxR84444x06NAhzZs3T5cuXXLxxRfnjTfeWOlrd+3aNV27ds3bb7+diy66KB07dkzLli2z3377ZcSIEaucZ9GiRbn66quz5557pmXLlmnbtm0+/vGPZ/z48atcX1tbm1tvvTW9evVK69at06pVqxxwwAG59dZb1+ZXBwDAJmy9TtvYZ599cuKJJ9Y9Hjp0aF577bWV1o0bNy79+vXLu+++m5NPPjldu3bNxIkTc+ONN+bee+/NpEmT0q5duyTJm2++mSS5+OKLkyQnnXRSdtlll0yZMiU//vGP89vf/jYTJkxY6W4b7777bo488sj84x//yDnnnJNFixblrrvuyplnnpm//e1vueSSS+rWLl68OH379s0TTzyRHj165NJLL82cOXNy55135oEHHsiIESNyyimn1K2vra3NWWedlREjRmS33XbLmWeemebNm+ehhx7Kpz/96fz5z3/O9ddfv8rf0ZIlS7JkyZK6xwsWLFjL3zIAAA3FOsXz8uXLkyT77bdfBg8eXLd97NixK8VzTU1NBgwYkHfeeSejR49e4VSMyy+/PN/5zndyxRVX5Gc/+1mSZNmyZXXf47777kv//v3r1n/3u9/Nl770pXz+85/PPffcs8L3eeONN7LbbrtlwoQJad68eZLkK1/5Svbbb798+ctfzic/+cnsuOOOSZJvf/vbeeKJJ3LWWWdl2LBhdUfLv/CFL6Rnz5658MILc/TRR2frrbdOktxyyy0ZMWJEzj///PzkJz9Js2bNkqTuPwa++93v5owzzsj++++/0u9qyJAh+drXvraWv2EAABqidTpt45///GeS1EXqmowfPz7Tpk3LMcccs9I5zIMGDUrbtm0zfPjwvPvuuyvs69ev3wrhnCQDBw5Mt27dct9999Udof533/zmN1eYaaeddsrAgQOzZMmS/PKXv6zbftttt6VZs2a57rrrVjjNZL/99st5552Xt99+OyNHjqzbftNNN2XLLbfMD3/4w7pwfu/nv/baa5NktaeHXHnllZk/f37dx4wZM1b3qwIAoIFbpyPPf//735MkrVq1et+1U6ZMSZL06dNnpX1bbbVVDjjggDz44IOZOnVq9tprr7p9hx9++MrDNm2aQw89NK+88kqeeeaZHHnkkSvsO+SQQ1b6nEMPPXSFORYsWJDp06fnAx/4QHbaaaeV1h9++OG5+eab8/TTT+ecc87JO++8k+eeey6dOnXKt771rZXWL126NEnywgsvrPLnb9GiRVq0aLHKfQAAbFrWKZ5nzpyZJOnUqdP7rn3vHN8OHTqscv8OO+ywwrqmTf81UseOHde4fv78+Stsb9euXaqrVz6Q/t73fW/92s7z97//PbW1tXn99dfXePrFokWLVrsPAIDGYZ3i+emnn06S7L777u+7tnXr1kmSOXPmrHL/7NmzV1jXtm3bFbavbn2bNm1W2P63v/0tNTU1KwX0e9/3vfVrO897/7v//vtn8uTJq/wcAAA2D+t0zvOYMWNSXV2dXr16ve/a/fbbL8m/Lib8T4sWLcrkyZOzxRZbZI899kiS9OjRY7Xrly9fnnHjxqWqqir77rvvCvuWLVuWiRMnrvQ5jz322ApztG7dOrvssktefvnlvP766yutf+/7vvf1t95663zgAx/IX/7yl7z99tvv9+MCANCIrXU8jx07Nn/84x/Tr1+/utvLrUmvXr3SvXv33H///RkzZswK+77xjW9k3rx5OeOMM+ou9Dv44IOz++67Z/To0Rk9evQK63/wgx9k2rRpOe6441b5vb/yla+scOHhzJkzc+ONN6ZFixY5/fTT67afd955Wbp0aa688srU1tbWbX/22WczdOjQtGnTZoVb8H3hC1/IO++8kwsuuGCVp2e88sorefXVV9/3dwEAwKZtrU7buPzyy/PjH/84yb8uhPv329QlqQvIwYMH58QTT8y+++6b6urqDB06tO7uGaecckq6dOmSiRMnZuzYsenevXuuu+66uq9RVVWVn/3sZznqqKNy3HHHrXCf59GjR2fHHXfMTTfdtNJsO+ywQxYtWpS99947xx13XN19nufNm5fvf//7dbepe+/nuO+++zJs2LD85S9/yRFHHJG5c+fmzjvvzLJly3LzzTfX3aYuSS666KJMmjQpt912W8aPH58jjzwynTp1ypw5c/LCCy/k8ccfz/Dhw9O1a9e1+XUCALCJqar990Ov77d4Ne8euCo///nPM2DAgLrHzz33XL7+9a9n7NixmT9/fjp16pQTTzwxV1111SqPIj/77LO55ppr6tZ37Ngxxx13XP77v/97pYsJ34vWKVOm5L/+678yatSovP3229lzzz1zxRVX5Iwzzljp6y9atCjf+ta3cuedd+bVV19Nq1atcsghh+QrX/lKevfuvcqf6a677srNN9+cp556Kv/4xz/Svn377LbbbjnuuONy7rnnFh2JX7BgQdq0aZPDm56UplXN3nc9rKsm27//8xHW131PjX7/RbCejtnt/U8ThfWxrPbd/H7RiMyfP7/uerfVWet4/s8oXp91G8p78bwpnDohnqkv4pn6IJ6pD+KZjW1t4nmdLhgEAIDN0VrF89VXX73SXS7WZx0AAGxK1uqCwf+8QHB91wEAwKZknd4kpaHZFM51BgBg0+ecZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBC4hkAAAqJZwAAKCSeAQCgkHgGAIBCTSs9wOaquu22qa5uXukxaMSWv/m3So/AZuBDN32u0iOwGfjnD5dUegQauZp/Lk4+W7bWkWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACgkngEAoJB4BgCAQuIZAAAKiWcAACjUION5zJgxqaqqyuc+97lV7p82bVqqq6vTr1+/dO3aNVVVVe/7MXTo0CTJ2LFjU1VVlcGDB2fcuHHp06dPtt5662yzzTY56aST8vLLL6/ye/7pT3/Kqaeemvbt26dFixbp1q1bLr300sybN29j/RoAAGhgmlZ6gFU54ogj0r179wwfPjzXX399WrVqtcL+W265JbW1tbngggsyc+bMvP3223X7Ro4cmWeeeSYDBw7MNttsU7d93333XeFrTJo0KUOGDMnRRx+dSy65JM8//3x+85vf5LHHHsukSZOyyy671K0dN25c+vXrl3fffTcnn3xyunbtmokTJ+bGG2/Mvffem0mTJqVdu3Yb41cBAEAD0iDjuaqqKhdeeGGuuOKK3H333TnvvPPq9i1btiy33XZb2rdvnxNOOCHNmjVb4XNfffXVPPPMM7n00kvTtWvX1X6PBx54ID/+8Y9z0UUX1W37yU9+ks9+9rMZOHBg7rnnniRJTU1NBgwYkHfeeSejR49Ov3796tZffvnl+c53vpMrrrgiP/vZz1b5fZYsWZIlS5bUPV6wYMFa/S4AAGg4GuRpG0ly/vnnp3nz5rnllltW2H7ffffljTfeyHnnnbdSOK+N3XffPRdccMEK2y644ILstttuue+++/Lmm28mScaPH59p06blmGOOWSGck2TQoEFp27Zthg8fnnfffXeV32fIkCFp06ZN3Ufnzp3XeWYAACqrwcbz9ttvn09+8pMZN25cXnjhhbrt78X0Zz7zmfX6+r169Up19Yo/fnV1dXr16pXa2to888wzSZIpU6YkSfr06bPS19hqq61ywAEHZPHixZk6deoqv8+VV16Z+fPn133MmDFjveYGAKByGmw8J6k7peK9YJ41a1buv//+HHbYYdl9993X62t36NBhjdvnz5+f5H9Ps1jd+h122GGFdf+pRYsWad269QofAABsmhp0PPfp0yd77rlnbr/99rz77rv5+c9/nuXLl690usW6mDNnzhq3t2nTJknqYnd162fPnr3COgAAGq8GHc9JcuGFF+bNN9/MyJEjc+utt2bbbbfNSSedtN5fd/z48ampqVlhW01NTSZMmJCqqqrss88+SZL99tsvyb9ucfefFi1alMmTJ2eLLbbIHnvssd4zAQDQsDX4eD7vvPPSsmXLXHbZZZk+fXrOOeectGzZcr2/7osvvpibb755hW0333xzXnzxxXz84x/P9ttvn+Rf50Z37949999/f8aMGbPC+m984xuZN29ezjjjjDRv3ny9ZwIAoGFrkLeq+3dt27bNKaeckmHDhiXJBjllI0n69euXL3zhC/nd736XD33oQ3n++edzzz33pF27drnxxhvr1lVXV2fo0KHp169f+vfvn1NOOSVdunTJxIkTM3bs2HTv3j3XXXfdBpkJAICGrcEfeU5Sd5/nnj175sMf/vAG+Zo9e/bMww8/nPnz5+f73/9+xo4dmxNPPDETJ05c4Q1SkqR3796ZNGlSTjjhhDz44IO5/vrr88orr2TgwIGZNGlS3VFqAAAatwZ/5Dn539vFlRx1Hjp0aN1bcb+f3r17r/Jc5lXZa6+9cvfddxetBQCgcWrwR54XL16cm266Kdtuu21OP/30So8DAMBmrMEeeR43blweeeSRPPDAA3nttdcyZMiQtGrVqtJjAQCwGWuw8TxmzJh87WtfS7t27XLZZZflS1/6UqVHAgBgM1dVW1tbW+khNicLFixImzZtckT7z6RptdvbsfHUzHur0iOwGZhx+UGVHoHNwD93X1LpEWjkav65ODM++7XMnz//fd/4rsGf8wwAAA2FeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAo1LTSA2yuls99M1VVzSo9BsB62embEyo9AsB6W1a7NDMK1zryDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFCoaaUHaOyWLFmSJUuW1D1esGBBBacBAGB9OPK8kQ0ZMiRt2rSp++jcuXOlRwIAYB1V1dbW1lZ6iMZsVUeeO3funD45IU2rmlVwMgAAkmRZ7dKMzajMnz8/rVu3XuNap21sZC1atEiLFi0qPQYAABuA0zYAAKCQeAYAgELieT1NmzYtL7zwQpYuXVrpUQAA2MjE83o64ogj8oEPfCCvv/56pUcBAGAjE88AAFDI3TbW06uvvlrpEQAAqCeOPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFCoaaUHAGATVt2k0hOwGaiqrqr0CDRyVbW1ybKytY48AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAIfEMAACFxDMAABQSzwAAUEg8AwBAoc06ngcPHpyqqqqMHTu20qMAALAJ2KzjGQAA1oZ4BgCAQvUezzNmzMjrr79e3992rTzxxBOpqamp9BgAADQw9RLPCxcuzNChQ9O3b9906dIlTz755Ar7586dm8suuyy77rprWrRokXbt2uWkk07Kn/70p5W+VteuXdO1a9f84x//yMCBA9OpU6e0aNEie++9d371q1+t8vvPmDEjZ5xxRtq2bZutttoqhx12WB599NHVznvqqadm5513zhVXXJHnn39+/X54AAAajY0Wz8uXL8/o0aNz1llnpWPHjjn//PPz1FNP5bzzzkuPHj3q1k2bNi37779/vve976V79+655JJL0r9//4wePTo9e/bM448/vtLXXrp0aY466qg8+OCDOemkk3L22Wdn2rRpOfXUU/Pggw+usPaNN97IIYcckl/+8pc56KCD8oUvfCFt27bNxz72sUyaNGmVs3/pS1/Ktttum29/+9v58Ic/nB49euR73/te5syZs2F/SQAAbFKqamtrazfkF3zmmWdy++23Z/jw4Zk9e3aaNWuWo446Kuecc06OP/74bLHFFius79WrVx5//PHcd9996devX932F198MQcccEC6du2aZ599tm57165d89prr+WEE07IXXfdlebNmydJHn744Rx55JHp169fRo8eXbd+wIABue222/KNb3wjX/3qV+u2//SnP81FF12UJPnDH/6QPn36rPSzPP3007njjjsyYsSIzJo1K02bNq37WU444YSVfpZVWbJkSZYsWVL3eMGCBencuXP65IQ0rWr2vp8P0KBVN6n0BGwGqqqrKj0Cjdyy2qX5w7JfZ/78+WnduvUa126QeJ41a1aGDx+e22+/Pc8991yS5OCDD87ZZ5+d008/Pe3atVvl502ZMiU9evTIpz71qfzsZz9baf//9//9f7nhhhvy3HPP5cMf/nCS/43n6dOnp1u3bius79q1axYuXJh58+YlSd599920adMmrVu3zmuvvZaWLVvWra2pqcmee+6Zl156abXx/O9rf//732fYsGH5zW9+k4ULF6Z169Y5+eSTc+655+ajH/1oqqpW/X/swYMH52tf+9pK28Uz0CiIZ+qBeGZjW5t4brohvmGvXr3y6quvpn379rn66qtz9tlnZ9ddd33fz3vvtIk5c+Zk8ODBK+1/4YUX6v73vXhOkm222WalcE6SnXbaKRMnTqx7PHXq1CxevDh9+/ZdIZyTpLq6Or169cpLL730vnNWV1fnyCOPzJFHHpkf//jHGTlyZH7605/m1ltvza233pqRI0fmhBNOWOXnXnnllfniF79Y9/i9I88AAGx6Nkg8f/jDH86rr76auXPnZvTo0WnXrl1OO+20bL/99mv8vLfeeitJct999+W+++5b7bpFixat8LhNmzarXNe0adMV7pIxf/78JEn79u1Xub5Dhw5rnO8/LV++PI899lhGjx6dyZMnJ0natWuXjh07rvZzWrRokRYtWqzV9wEAoGHaIBcM3nPPPXnxxRdz1VVXZc6cObnkkkvSqVOn9O/fP8OHD18pft/z3mHxH/zgB6mtrV3tx3nnnbdOc70X2XPnzl3l/tILAJ966qlcdtll2WmnndKvX7/ceeedOfroozNq1KjMmjUrBx988DrNBwDApmWD3W1jt912yzXXXJPp06fnkUceyYABAzJhwoScddZZ6dChQ84+++zcf//9WbZsWd3nvBed/36qxYa0++67p2XLlpk8eXIWL168wr6amppMmDBhtZ87ffr0XHPNNdlzzz1zwAEH1N0N5Cc/+Ulmz56du+++O8cff3yaNXPeMgDA5mKD36quqqoqH/3oR3PzzTdn9uzZufPOO9OnT5/ceeed6d+/f3bccce6288ddNBBOfjggzNixIjceeedK32tmpqaPPLII+s8S4sWLXLqqadm7ty5+e53v7vCvltuuSUvvvjiKj/v+OOPT/fu3TNo0KAsX748gwcPzrRp0zJu3LhceOGF2WabbdZ5JgAANl0b5Jzn1WnZsmVOPfXUnHrqqXnzzTczfPjwDBs2LLNnz65bM2LEiBx++OE5/fTT873vfS89evTIFltskb/+9a+ZOHFi3nzzzZWOGq+N6667Lg8//HCuuuqqjBs3Lvvtt1/+8pe/5He/+13dvaL/0+uvv57PfvazOeecc/KRj3xknb83AACNy0aN53+3/fbbZ+DAgRk4cGCWL19et71bt26ZMmVKbrjhhowcOTI///nP06RJk+ywww756Ec/mpNPPnm9vu8OO+yQCRMm5PLLL88DDzyQRx99NPvvv38eeuih/P73v19lPD/xxBNp0sTtlwAAWNEGf5MU1mzBggVp06aN+zwDjYP7PFMP3OeZjW1t7vO80d6eGwAAGhvxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFCoaaUHAGATVrO80hOwGaitqfQENHa1tcuK1zryDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFCoaaUHaOyWLFmSJUuW1D1esGBBBacBAGB9OPK8kQ0ZMiRt2rSp++jcuXOlRwIAYB1V1dbW1lZ6iMZsVUeeO3funD45IU2rmlVwMgAAkmRZ7dKMzajMnz8/rVu3XuNap21sZC1atEiLFi0qPQYAABuA0zYAAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKCQeAYAgELiGQAAColnAAAoJJ4BAKBQ00oPsLmpra1NkizL0qS2wsMAAPCvLsv/dtqaiOd6tnDhwiTJuPyuwpMAAPDvFi5cmDZt2qxxTVVtSWKzwdTU1GTWrFnZeuutU1VVVelxNgkLFixI586dM2PGjLRu3brS49BIeZ5RHzzPqA+eZ2uvtrY2CxcuTKdOnVJdveazmh15rmfV1dXZaaedKj3GJql169b+EWCj8zyjPnieUR88z9bO+x1xfo8LBgEAoJB4BgCAQuKZBq9Fixa5+uqr06JFi0qPQiPmeUZ98DyjPniebVwuGAQAgEKOPAMAQCHxDAAAhcQzAAAUEs8AAFBIPAMAQCHxDAAAhcQzAAAUEs8AAFDo/wclyIySIMq/sgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jouPDZQH_CM",
        "outputId": "b3b51398-4c33-4a7c-af25-5478d941d0cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for seq_index in range(0, 20000, 500):\n",
        "    string_i = input_texts[seq_index]\n",
        "    translate(string_i[7:-5].lower(), False)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> go . <end>\n",
            "Predicted translation: идите . <end> \n",
            "\n",
            "Input: <start> who ate ? <end>\n",
            "Predicted translation: кто съел ? <end> \n",
            "\n",
            "Input: <start> touch it . <end>\n",
            "Predicted translation: потрогайте его . <end> \n",
            "\n",
            "Input: <start> i m dirty . <end>\n",
            "Predicted translation: я грязная . <end> \n",
            "\n",
            "Input: <start> tom s shy . <end>\n",
            "Predicted translation: том робкий . <end> \n",
            "\n",
            "Input: <start> i envy you . <end>\n",
            "Predicted translation: я тебе завидую . <end> \n",
            "\n",
            "Input: <start> it s green . <end>\n",
            "Predicted translation: оно зел ное . <end> \n",
            "\n",
            "Input: <start> we ll cook . <end>\n",
            "Predicted translation: мы будем готовить . <end> \n",
            "\n",
            "Input: <start> have a look . <end>\n",
            "Predicted translation: посмотри . <end> \n",
            "\n",
            "Input: <start> i saved you . <end>\n",
            "Predicted translation: я вас спас . <end> \n",
            "\n",
            "Input: <start> is it there ? <end>\n",
            "Predicted translation: он там ? <end> \n",
            "\n",
            "Input: <start> stop crying . <end>\n",
            "Predicted translation: хватит лить сл зы ! <end> \n",
            "\n",
            "Input: <start> we miss you . <end>\n",
            "Predicted translation: мы по тебе скучаем . <end> \n",
            "\n",
            "Input: <start> are you tall ? <end>\n",
            "Predicted translation: вы высокие ? <end> \n",
            "\n",
            "Input: <start> hey , wake up ! <end>\n",
            "Predicted translation: эй , вставай ! <end> \n",
            "\n",
            "Input: <start> i was lonely . <end>\n",
            "Predicted translation: я был одинок . <end> \n",
            "\n",
            "Input: <start> i m very hot . <end>\n",
            "Predicted translation: мне очень жарко . <end> \n",
            "\n",
            "Input: <start> must i hurry ? <end>\n",
            "Predicted translation: мне спешить ? <end> \n",
            "\n",
            "Input: <start> they re ugly . <end>\n",
            "Predicted translation: они некрасивые . <end> \n",
            "\n",
            "Input: <start> we have time . <end>\n",
            "Predicted translation: у нас есть время . <end> \n",
            "\n",
            "Input: <start> you re scary . <end>\n",
            "Predicted translation: ты пугаешь . <end> \n",
            "\n",
            "Input: <start> don t be mean . <end>\n",
            "Predicted translation: не будь таким вредным . <end> \n",
            "\n",
            "Input: <start> i am divorced . <end>\n",
            "Predicted translation: я развед н . <end> \n",
            "\n",
            "Input: <start> i miss boston . <end>\n",
            "Predicted translation: мне не хватает бостона . <end> \n",
            "\n",
            "Input: <start> i ll get some . <end>\n",
            "Predicted translation: я получу некоторое . <end> \n",
            "\n",
            "Input: <start> is tom around ? <end>\n",
            "Predicted translation: том рядом ? <end> \n",
            "\n",
            "Input: <start> listen to tom . <end>\n",
            "Predicted translation: послушай тома . <end> \n",
            "\n",
            "Input: <start> stop scowling . <end>\n",
            "Predicted translation: прекрати хмуриться ! <end> \n",
            "\n",
            "Input: <start> tom has a cat . <end>\n",
            "Predicted translation: у тома есть кошка . <end> \n",
            "\n",
            "Input: <start> turn the page . <end>\n",
            "Predicted translation: переверни страницу . <end> \n",
            "\n",
            "Input: <start> who was wrong ? <end>\n",
            "Predicted translation: кто был не прав ? <end> \n",
            "\n",
            "Input: <start> aren t you tom ? <end>\n",
            "Predicted translation: вы не том ? <end> \n",
            "\n",
            "Input: <start> do you promise ? <end>\n",
            "Predicted translation: обещаешь ? <end> \n",
            "\n",
            "Input: <start> he is handsome . <end>\n",
            "Predicted translation: он красивый . <end> \n",
            "\n",
            "Input: <start> i got up early . <end>\n",
            "Predicted translation: я рано встала . <end> \n",
            "\n",
            "Input: <start> i said shut up ! <end>\n",
            "Predicted translation: я сказал , заткнись . <end> \n",
            "\n",
            "Input: <start> i m an old man . <end>\n",
            "Predicted translation: я старый . <end> \n",
            "\n",
            "Input: <start> it was serious . <end>\n",
            "Predicted translation: это было серь зно . <end> \n",
            "\n",
            "Input: <start> mary is a girl . <end>\n",
            "Predicted translation: мэри девочка . <end> \n",
            "\n",
            "Input: <start> tell everybody . <end>\n",
            "Predicted translation: расскажите всем и каждому . <end> \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FHi2kWbfNwHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "891PdmlWNTUF"
      },
      "outputs": [],
      "source": []
    }
  ]
}